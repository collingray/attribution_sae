{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%env TOKENIZERS_PARALLELISM=false\n",
    "%env WANDB_SILENT=true"
   ],
   "id": "b645f466c668d235",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import wandb\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from grad_buffer import GradBuffer, GradBufferConfig\n",
    "from model import AttributionSAE, AttributionSAEConfig\n",
    "import loss"
   ],
   "id": "46b4783750708577",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cfg = {\n",
    "    'model_name': 'pythia-70m',\n",
    "    'dataset_name': 'wikitext',\n",
    "    'dataset_split': 'train',\n",
    "    'dataset_config': 'wikitext-103-v1',\n",
    "    'n_dim': 512,\n",
    "    'expansion_factor': 32,\n",
    "    'batch_size': 32,\n",
    "    'total_steps': 50000,\n",
    "    'parallelism': 48,\n",
    "    'device': 'cuda',\n",
    "    'dtype': 'bfloat16',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "torch.manual_seed(cfg['seed'])"
   ],
   "id": "f23ac9b7d7d1695d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sweep_config = {\n",
    "    'lr': [1e-2, 7e-3, 5.5e-3, 4e-3, 3e-3, 2e-3, 1.6e-3, 1.2e-3, 8.6e-4, 6.3e-4, 4.6e-4, 3.4e-4, 2.5e-4, 1.8e-4, 1.4e-4, 1e-4],\n",
    "    'λ': [3e-2],\n",
    "    'α': [0],\n",
    "    'β': [1],\n",
    "}\n",
    "\n",
    "sweep_configs = [\n",
    "    {\n",
    "        'lr': lr,\n",
    "        'λ': λ,\n",
    "        'α': α,\n",
    "        'β': β,\n",
    "    }\n",
    "    for lr in sweep_config['lr']\n",
    "    for λ in sweep_config['λ']\n",
    "    for α in sweep_config['α']\n",
    "    for β in sweep_config['β']\n",
    "]"
   ],
   "id": "1122be7fc0bcda88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "buffer_config = GradBufferConfig(\n",
    "    model_name=cfg['model_name'],\n",
    "    layers=list(range(6)),\n",
    "    buffer_size=2**16,\n",
    "    buffer_device='cpu',\n",
    "    min_capacity=3*(2**14),\n",
    "    dataset_name=cfg['dataset_name'],\n",
    "    dataset_split=cfg['dataset_split'],\n",
    "    dataset_config=cfg['dataset_config'],\n",
    "    max_seq_length=512,\n",
    "    device=cfg['device'],\n",
    "    dtype=cfg['dtype'],\n",
    "    seed=cfg['seed'],\n",
    ")"
   ],
   "id": "ea5eb5c425206ac6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "buffer = GradBuffer(buffer_config)",
   "id": "645d73a7ae7cc468",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_config = AttributionSAEConfig(\n",
    "    n_dim=cfg['n_dim'],\n",
    "    m_dim=cfg['n_dim']*cfg['expansion_factor'],\n",
    "    device=cfg['device'],\n",
    "    dtype=cfg['dtype'],\n",
    ")"
   ],
   "id": "c9a13257145fd9e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "wandb.init(\n",
    "    project='AttributionSAE Experiments',\n",
    "    entity='collingray',\n",
    "    group='sweeps',\n",
    "    name=input(\"Wandb Run Name: \"),\n",
    "    config={**cfg, **{f'sweeps.{i}': c for i, c in enumerate(sweep_configs)}},\n",
    ")"
   ],
   "id": "905e9dc284dbcfec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_models(configs, buffer, offset, report_interval=10):\n",
    "    models = [AttributionSAE(model_config) for _ in range(len(configs))]\n",
    "    optimizers = [torch.optim.Adam(models[i].parameters(), lr=config['lr']) for i, config in enumerate(configs)]\n",
    "    schedulers = [torch.optim.lr_scheduler.OneCycleLR(optimizers[i], max_lr=config['lr'], total_steps=cfg['total_steps']) for i, config in enumerate(configs)]\n",
    "    \n",
    "    for step in tqdm(range(cfg['total_steps'])):\n",
    "\n",
    "        x, grad = buffer.next(cfg['batch_size'])\n",
    "        x = x.to(cfg['device'])\n",
    "        grad = grad.unsqueeze(-2).to(cfg['device'])\n",
    "        \n",
    "        for i in range(len(configs)):\n",
    "            config = configs[i]\n",
    "            model = models[i]\n",
    "            optimizer = optimizers[i]\n",
    "            scheduler = schedulers[i]\n",
    "            \n",
    "            y, f = model(x)\n",
    "            \n",
    "            dictionary = model.W_d.weight\n",
    "        \n",
    "            reconstruction = loss.reconstruction(x, y)    \n",
    "            act_sparsity = loss.act_sparsity(f)\n",
    "            grad_sparsity = loss.grad_sparsity(f, grad, dictionary)\n",
    "            unexplained = loss.unexplained(x, y, grad)\n",
    "            l0 = (f != 0).sum(-1).float().mean()\n",
    "            fvu = reconstruction / x.var()\n",
    "            \n",
    "            total_loss = reconstruction + config['λ']*act_sparsity + config['α']*grad_sparsity + config['β']*unexplained\n",
    "            \n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            if step % report_interval == 0:\n",
    "                wandb.log({\n",
    "                        str(offset + i): {\n",
    "                            'loss': total_loss.item(),\n",
    "                            'reconstruction': reconstruction.item(),\n",
    "                            'act_sparsity': act_sparsity.item(),\n",
    "                            'grad_sparsity': grad_sparsity.item(),\n",
    "                            'unexplained': unexplained.item(),\n",
    "                            'l0': l0.item(),\n",
    "                            'fvu': fvu.item(),\n",
    "                        }\n",
    "                    },\n",
    "                    step=step // report_interval\n",
    "                )\n"
   ],
   "id": "25c410ca9fe5a2ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(-(len(sweep_configs) // -cfg['parallelism'])):    \n",
    "    train_models(sweep_configs[i*cfg['parallelism']:(i+1)*cfg['parallelism']], buffer, i*cfg['parallelism'])"
   ],
   "id": "71472205ee42c063",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "wandb.finish()",
   "id": "f8186ec64ac9102b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "117cc3b401100763",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
